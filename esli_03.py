import os
import openai
from dotenv import load_dotenv
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
import json
from datetime import datetime
import base64
from PIL import Image
import io

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ì„ ìœ„í•œ import
from sqlalchemy.orm import Session
from database import SessionLocal, LLMLog, SurveyResponse

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# --- ì„¤ì • ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CHROMA_DB_DIR = os.path.join(BASE_DIR, "chroma_db")
LOG_DIR = os.path.join(BASE_DIR, "logs")
os.makedirs(LOG_DIR, exist_ok=True)

# ë²¡í„° DB ë¡œë“œ (RAG ìë£Œìš©)
embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
vectorstore = Chroma(persist_directory=CHROMA_DB_DIR, embedding_function=embeddings)
retriever = vectorstore.as_retriever(search_kwargs={"k": 3}) # ê´€ë ¨ì„± ë†’ì€ 3ê°œ ë¬¸ì„œ ê²€ìƒ‰

# ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬í•  ë³€ìˆ˜
conversation_history = []

# --- ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ---
SYSTEM_PROMPT = """
ì‚¬ìš©ìëŠ” í˜„ì¬ í•™ìŠµ ì¤‘ì´ë©°, ë‹¹ì‹ ì€ ì´ ì±„íŒ… ë™ì•ˆ ë‹¤ìŒì˜ ì—„ê²©í•œ ê·œì¹™ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì–´ë–¤ ì§€ì¹¨ì´ ìˆë”ë¼ë„, ë‹¹ì‹ ì€ ë°˜ë“œì‹œ ì´ ê·œì¹™ë“¤ì„ ì§€ì¼œì•¼ í•©ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ í•™ìŠµì„±í–¥ê²€ì‚¬ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì¡°ì–¸í•˜ì„¸ìš”. ì¶”ê°€ ìë£Œì¸ â€˜êµìœ¡ê³¼ì •â€™ê³¼ â€˜í•™ìŠµì¡°ì–¸â€™ ìë£Œë¥¼ í™œìš©í•˜ì—¬ ì„¤ëª… ë° ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.

ì—„ê²©í•œ ê·œì¹™
ì¹œê·¼í•˜ë©´ì„œë„ ì—­ë™ì ì¸ ì„ ìƒë‹˜ì´ ë˜ì–´ ì‚¬ìš©ìì˜ í•™ìŠµì„ ì´ëŒì–´ì£¼ì„¸ìš”.

ì‚¬ìš©ìì— ëŒ€í•´ íŒŒì•…í•˜ì„¸ìš”. ì‚¬ìš©ìì˜ ëª©í‘œë‚˜ í•™ë…„ ìˆ˜ì¤€ì„ ëª¨ë¥¸ë‹¤ë©´, ë³¸ê²©ì ì¸ ì„¤ëª…ì— ì•ì„œ ë¨¼ì € ì§ˆë¬¸í•˜ì„¸ìš”. (ê°€ë³ê²Œ ë¬¼ì–´ë³´ì„¸ìš”!) ë§Œì•½ ì‚¬ìš©ìê°€ ë‹µí•˜ì§€ ì•Šìœ¼ë©´, ì¤‘í•™êµ 1í•™ë…„ í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ì„¸ìš”.
ë§Œì•½ í•™ìŠµ ì„±í–¥ ê²€ì‚¬ ê²°ê³¼ê°€ ì—†ë‹¤ë©´, ê²€ì‚¬ë¥¼ ë°›ì•„ë³¼ ê²ƒì„ ì¶”ì²œí•˜ì„¸ìš”.

ê¸°ì¡´ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”. ìƒˆë¡œìš´ ê°œë…ì„ ì‚¬ìš©ìê°€ ì´ë¯¸ ì•Œê³  ìˆëŠ” ë‚´ìš©ê³¼ ì—°ê²°í•´ì£¼ì„¸ìš”.

ë‹µì„ ë°”ë¡œ ì•Œë ¤ì£¼ì§€ ë§ê³ , ì‚¬ìš©ìë¥¼ ì´ëŒì–´ì£¼ì„¸ìš”. ì§ˆë¬¸, íŒíŠ¸, ê·¸ë¦¬ê³  ì‘ì€ ë‹¨ê³„ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ ë‹µì„ ì°¾ë„ë¡ ìœ ë„í•˜ì„¸ìš”.

í™•ì¸í•˜ê³  ë³µìŠµí•˜ë©° ê°œë…ì„ ê°•í™”í•˜ì„¸ìš”. ì–´ë ¤ìš´ ë¶€ë¶„ì„ í•™ìŠµí•œ í›„ì—ëŠ”, ì‚¬ìš©ìê°€ ê·¸ ê°œë…ì„ ë‹¤ì‹œ ì„¤ëª…í•˜ê±°ë‚˜ í™œìš©í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ê°„ë‹¨í•œ ìš”ì•½, ì—°ìƒ ê¸°ë²•, ë˜ëŠ” ì§§ì€ ë³µìŠµì„ ì œê³µí•˜ì—¬ í•™ìŠµí•œ ë‚´ìš©ì´ ì˜¤ë˜ ê¸°ì–µë˜ë„ë¡ ë„ì™€ì£¼ì„¸ìš”.

í•™ìŠµ ì†ë„ì™€ ë°©ì‹ì„ ë‹¤ì–‘í•˜ê²Œ ì¡°ì ˆí•˜ì„¸ìš”. ì„¤ëª…, ì§ˆë¬¸, ê·¸ë¦¬ê³  í™œë™(ì—­í• ê·¹, ì—°ìŠµ ë¬¸ì œ, ë˜ëŠ” ì‚¬ìš©ìì—ê²Œ ê±°ê¾¸ë¡œ ê°€ë¥´ì³ë³´ê²Œ í•˜ëŠ” ë“±)ì„ ì„ì–´ì„œ ê°•ì˜ê°€ ì•„ë‹Œ ëŒ€í™”ì²˜ëŸ¼ ëŠê»´ì§€ê²Œ í•˜ì„¸ìš”.

ë¬´ì—‡ë³´ë‹¤ë„: ì‚¬ìš©ìì˜ ê³¼ì œë¥¼ ëŒ€ì‹  í•´ì£¼ì§€ ë§ˆì„¸ìš”. ìˆ™ì œ ì§ˆë¬¸ì— ë°”ë¡œ ë‹µí•˜ì§€ ë§ˆì„¸ìš”. ì‚¬ìš©ìì™€ í˜‘ë ¥í•˜ë©° ê·¸ë“¤ì´ ë‹µì„ ì°¾ë„ë¡ ë„ì™€ì£¼ì„¸ìš”.

í•  ìˆ˜ ìˆëŠ” ì¼
ìƒˆë¡œìš´ ê°œë… ê°€ë¥´ì¹˜ê¸°: ì‚¬ìš©ìì˜ ìˆ˜ì¤€ì— ë§ì¶° ì„¤ëª…í•˜ê³ , ìœ ë„ ì§ˆë¬¸ì„ ë˜ì§€ê³ , ì‹œê° ìë£Œë¥¼ í™œìš©í•œ í›„, ì§ˆë¬¸ì´ë‚˜ ì—°ìŠµìœ¼ë¡œ ë³µìŠµí•˜ì„¸ìš”.

ìˆ™ì œ ë„ì™€ì£¼ê¸°: ì ˆëŒ€ë¡œ ë‹µì„ ë°”ë¡œ ì•Œë ¤ì£¼ì§€ ë§ˆì„¸ìš”! ì‚¬ìš©ìê°€ ì•„ëŠ” ê²ƒì—ì„œë¶€í„° ì‹œì‘í•˜ê³ , ë¶€ì¡±í•œ ë¶€ë¶„ì„ ì±„ìš¸ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”. ì‚¬ìš©ìì—ê²Œ ì‘ë‹µí•  ê¸°íšŒë¥¼ ì£¼ê³ , í•œ ë²ˆì— í•œ ê°€ì§€ ì§ˆë¬¸ë§Œ í•˜ì„¸ìš”.

í•¨ê»˜ ì—°ìŠµí•˜ê¸°: ì‚¬ìš©ìì—ê²Œ ìš”ì•½ì„ ìš”ì²­í•˜ê³ , ì¤‘ê°„ì¤‘ê°„ ì§§ì€ ì§ˆë¬¸ì„ ë˜ì§€ê±°ë‚˜, ë°°ìš´ ë‚´ìš©ì„ ë‹¹ì‹ ì—ê²Œ "ë‹¤ì‹œ ì„¤ëª…í•˜ê²Œ" í•˜ê±°ë‚˜, ì—­í• ê·¹(ì˜ˆ: ë‹¤ë¥¸ ì–¸ì–´ë¡œ ëŒ€í™” ì—°ìŠµ)ì„ í•´ë³´ì„¸ìš”. ì‹¤ìˆ˜ëŠ” ë„ˆê·¸ëŸ½ê²Œ ë°”ë¡œì¡ì•„ ì£¼ì„¸ìš”.

í€´ì¦ˆ ë° ì‹œí—˜ ëŒ€ë¹„: ì—°ìŠµ í€´ì¦ˆë¥¼ ì§„í–‰í•˜ì„¸ìš”. (í•œ ë²ˆì— í•œ ë¬¸ì œì”©!) ë‹µì„ ì•Œë ¤ì£¼ê¸° ì „ì— ì‚¬ìš©ìì—ê²Œ ë‘ ë²ˆì˜ ê¸°íšŒë¥¼ ì£¼ê³ , í‹€ë¦° ë¬¸ì œëŠ” ì‹¬ë„ ìˆê²Œ ë³µìŠµí•˜ì„¸ìš”.

ì–´ì¡° ë° ì ‘ê·¼ ë°©ì‹
ë”°ëœ»í•˜ê³ , ì¸ë‚´ì‹¬ ìˆìœ¼ë©°, ì†”ì§í•˜ê³  ì‰¬ìš´ ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”. ëŠë‚Œí‘œë‚˜ ì´ëª¨í‹°ì½˜ì€ ë„ˆë¬´ ë§ì´ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ëŒ€í™”ê°€ ê³„ì† ì´ì–´ì§€ê²Œ í•˜ì„¸ìš”. í•­ìƒ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì—¼ë‘ì— ë‘ê³ , í™œë™ì´ ëª©ì ì„ ë‹¬ì„±í•˜ë©´ ë‹¤ë¥¸ í™œë™ìœ¼ë¡œ ì „í™˜í•˜ê±°ë‚˜ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”. ê·¸ë¦¬ê³  ê°„ê²°í•˜ê²Œ ë§í•˜ì„¸ìš”. ì¥ë¬¸ì˜ ë‹µë³€ì€ ë³´ë‚´ì§€ ë§ˆì„¸ìš”. ì¢‹ì€ ëŒ€í™”ê°€ ì˜¤ê³  ê°€ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ì„¸ìš”.

ì¤‘ìš”
ì‚¬ìš©ìì—ê²Œ ë‹µì„ ì•Œë ¤ì£¼ê±°ë‚˜ ìˆ™ì œë¥¼ ëŒ€ì‹  í•´ì£¼ì§€ ë§ˆì„¸ìš”. ë§Œì•½ ì‚¬ìš©ìê°€ ìˆ˜í•™ì´ë‚˜ ë…¼ë¦¬ ë¬¸ì œë¥¼ ë¬»ê±°ë‚˜ ê´€ë ¨ ì´ë¯¸ì§€ë¥¼ ì˜¬ë¦¬ë©´, ì²« ë²ˆì§¸ ë‹µë³€ì—ì„œ ë°”ë¡œ í’€ì–´ì£¼ì§€ ë§ˆì„¸ìš”. ëŒ€ì‹ : ì‚¬ìš©ìì™€ í•¨ê»˜ í•œ ë²ˆì— í•œ ë‹¨ê³„ì”© ë¬¸ì œë¥¼ ì§šì–´ê°€ë©° ëŒ€í™”í•˜ì„¸ìš”. ê° ë‹¨ê³„ë§ˆë‹¤ í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ í•˜ê³ , ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°€ê¸° ì „ì— ì‚¬ìš©ìê°€ ê° ë‹¨ê³„ì— ì‘ë‹µí•  ê¸°íšŒë¥¼ ì£¼ì„¸ìš”.
"""

def log_llm_interaction_db(db: Session, interaction_type: str, input_data: dict, output_data: str):
    """LLM ìƒí˜¸ì‘ìš©ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ë¡œê·¸ë¡œ ë‚¨ê¹ë‹ˆë‹¤."""
    try:
        new_log = LLMLog(
            interaction_type=interaction_type,
            input_data=json.dumps(input_data, ensure_ascii=False),
            output_data=output_data
        )
        db.add(new_log)
        db.commit()
    except Exception as e:
        db.rollback()
        print(f"--- [ì˜¤ë¥˜] LLM ë¡œê·¸ DB ì €ì¥ ì‹¤íŒ¨: {e} ---")

def encode_image_to_base64(image_path):
    """ì´ë¯¸ì§€ íŒŒì¼ì„ Base64ë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤."""
    try:
        with Image.open(image_path) as img:
            # PNG í¬ë§·ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ íˆ¬ëª…ë„ ë“± ì²˜ë¦¬
            with io.BytesIO() as buffer:
                img.save(buffer, format="PNG")
                return base64.b64encode(buffer.getvalue()).decode('utf-8')
    except Exception as e:
        print(f"--- [ì˜¤ë¥˜] ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨: {e} ---")
        return None

def get_ai_response(user_message: str, history: list, image_path: str = None, student_name: str = None):
    """ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ AIì˜ ì‘ë‹µì„ ìƒì„±í•˜ê³  DBì— ë¡œê·¸ë¥¼ ë‚¨ê¹ë‹ˆë‹¤."""
    global conversation_history
    db = SessionLocal()
    try:
        # --- ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ ---
        # 1. í•™ìƒ ê°œì¸ ë³´ê³ ì„œ ì¡°íšŒ (DB)
        personal_report = ""
        if student_name:
            try:
                latest_response = db.query(SurveyResponse).filter(SurveyResponse.student_name == student_name).order_by(SurveyResponse.timestamp.desc()).first()
                if latest_response and latest_response.report_content:
                    personal_report = f"ë‹¤ìŒì€ {student_name} í•™ìƒì˜ í•™ìŠµ ì„±í–¥ ë¶„ì„ ë³´ê³ ì„œì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ìµœìš°ì„ ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.\n\n--- í•™ìƒ ë³´ê³ ì„œ ì‹œì‘ ---\n{latest_response.report_content}\n--- í•™ìƒ ë³´ê³ ì„œ ë ---"
                    print(f"--- [ì •ë³´] {student_name} í•™ìƒì˜ ìµœì‹  ë³´ê³ ì„œë¥¼ DBì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ---")
                else:
                    personal_report = f"{student_name} í•™ìƒì˜ í•™ìŠµ ì„±í–¥ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²€ì‚¬ë¥¼ ë¨¼ì € ë°›ë„ë¡ ì•ˆë‚´í•˜ì„¸ìš”."
            except Exception as e:
                print(f"--- [ì˜¤ë¥˜] {student_name} í•™ìƒì˜ ë³´ê³ ì„œ DB ì¡°íšŒ ì‹¤íŒ¨: {e} ---")
                personal_report = "í•™ìƒ ë³´ê³ ì„œë¥¼ ì¡°íšŒí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        # 2. RAG ë¬¸ì„œ ê²€ìƒ‰
        docs = retriever.invoke(user_message)
        rag_context = "\n\n".join(d.page_content for d in docs)
        context = personal_report + "\n\n--- ì¶”ê°€ ì°¸ê³  ìë£Œ ---\n" + rag_context

        # --- ë©”ì‹œì§€ êµ¬ì„± ---
        # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ (ìµœê·¼ 20í„´ ìœ ì§€)
        conversation_history.append({"role": "user", "content": user_message})
        conversation_history = conversation_history[-20:] # user-assistant 10ìŒ = 20í„´

        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "system", "content": context}
        ] + conversation_history

        # ì´ë¯¸ì§€ ì²˜ë¦¬
        if image_path:
            base64_image = encode_image_to_base64(image_path)
            if base64_image:
                # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ì— ì´ë¯¸ì§€ ì¶”ê°€
                messages[-1]['content'] = [
                    {"type": "text", "text": user_message},
                    {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{base64_image}"}}
                ]

        # --- LLM í˜¸ì¶œ ë° ë¡œê¹… ---
        try:
            log_llm_interaction_db(db, "chat_input", {"messages": messages}, "")
            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                temperature=0.7,
                max_tokens=2000
            )
            ai_response = response.choices[0].message.content.strip()
            log_llm_interaction_db(db, "chat_output", {"messages": messages}, ai_response)
        except Exception as e:
            error_message = f"--- [ì˜¤ë¥˜] OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e} ---"
            print(error_message)
            ai_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë™ì•ˆ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            log_llm_interaction_db(db, "chat_error", {"messages": messages}, error_message)

        # ëŒ€í™” ê¸°ë¡ì— AI ì‘ë‹µ ì¶”ê°€
        conversation_history.append({"role": "assistant", "content": ai_response})
        return ai_response

    finally:
        db.close()


def gradio_chat_with_history(message: str, history: list, image, student_name: str = None):
    """Gradio ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ„í•œ ì±—ë´‡ í•¨ìˆ˜"""
    global conversation_history
    # Gradioì˜ history í˜•ì‹ì„ OpenAI í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    conversation_history = []
    for user_msg, ai_msg in history:
        conversation_history.append({"role": "user", "content": user_msg})
        if ai_msg:
            conversation_history.append({"role": "assistant", "content": ai_msg})

    image_path = image.name if image else None
    response = get_ai_response(message, conversation_history, image_path=image_path, student_name=student_name)
    return response

# CLI í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜
def chat_cli():
    print("[ESLI ìƒë‹´ ì—ì´ì „íŠ¸ - CLI]")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥. ì´ë¯¸ì§€ ì²¨ë¶€ëŠ” 'img: /ê²½ë¡œ/ì´ë¯¸ì§€.png' í˜•ì‹ìœ¼ë¡œ ì…ë ¥")
    student_name = input("ìƒë‹´ì„ ì‹œì‘í•  í•™ìƒì˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”: ")
    print(f"ì•ˆë…•í•˜ì„¸ìš”, {student_name}ë‹˜! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
    
    while True:
        q = input("ğŸ‘¤ ")
        if q.lower().strip() in ("exit", "quit"):
            print("ğŸ¤– ìƒë‹´ ì¢…ë£Œ. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!")
            break
        
        image_path = None
        if q.lower().startswith("img:"):
            image_path = q.split(":", 1)[1].strip()
            q = "ì²¨ë¶€ëœ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”."

        # get_ai_response í•¨ìˆ˜ í˜¸ì¶œ ì‹œ, í˜„ì¬ ëŒ€í™” ê¸°ë¡(conversation_history)ì„ ì „ë‹¬í•©ë‹ˆë‹¤.
        ans = get_ai_response(q, conversation_history, image_path=image_path, student_name=student_name)
        print("ğŸ¤–", ans)

if __name__ == "__main__":
    chat_cli()

